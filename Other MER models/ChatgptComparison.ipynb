{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdNjjbeW-2Ty"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxqYgkW-_UDA",
        "outputId": "0fb81add-4252-48d8-fc60-445728a97805"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.78.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade openai \n",
        "!pip install jiwer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PhAlWAen511",
        "outputId": "8af4f2a3-88ab-47dd-d2ef-b370aa1a41e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BtmQ5tAbylD-"
      },
      "outputs": [],
      "source": [
        "#same as above but with CER\n",
        "\n",
        "import os\n",
        "import json\n",
        "import base64\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "from openai import OpenAI\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "import jiwer\n",
        "\n",
        "# âœ… Initialize OpenAI client (new API version)\n",
        "client = OpenAI(api_key=\"your_api_key\")\n",
        "\n",
        "# === CONFIGURATION ===\n",
        "image_folder = \"/content/drive/MyDrive/Printed_Split_set/test/Images\"\n",
        "gt_txt_file = \"/content/drive/MyDrive/Printed_Split_set/test/Latex.txt\"\n",
        "output_txt = \"./LATEST_PRINTED_gpt4o_detailed_output.txt\"\n",
        "max_samples = None  # Set to integer to limit, or None for all\n",
        "# =====================\n",
        "\n",
        "# === Tokenizer for LaTeX math\n",
        "def tokenize_latex(expr):\n",
        "    return re.findall(r'(\\\\[a-zA-Z]+|[{}_^=+\\-*/(),]|[a-zA-Z]+|\\d+)', expr)\n",
        "\n",
        "# === Tokenizer Transform for CER\n",
        "class TokenizeTransform(jiwer.transforms.AbstractTransform):\n",
        "    def process_string(self, s: str):\n",
        "        return tokenize_latex(s)\n",
        "    def process_list(self, tokens: list[str]):\n",
        "        return [self.process_string(token) for token in tokens]\n",
        "\n",
        "# === CER Calculation\n",
        "def compute_cer(truth_and_output: list[tuple[str, str]]):\n",
        "    ground_truth, model_output = zip(*truth_and_output)\n",
        "    return jiwer.cer(\n",
        "        truth=list(ground_truth),\n",
        "        hypothesis=list(model_output),\n",
        "        reference_transform=TokenizeTransform(),\n",
        "        hypothesis_transform=TokenizeTransform()\n",
        "    )\n",
        "\n",
        "# === BLEU & Edit Distance per sample\n",
        "def compute_individual_metrics(pred, gt):\n",
        "    smoothie = SmoothingFunction().method4\n",
        "    bleu = sentence_bleu([tokenize_latex(gt)], tokenize_latex(pred), smoothing_function=smoothie)\n",
        "    return bleu\n",
        "\n",
        "# === Encode Image to Base64\n",
        "def encode_image(image_path):\n",
        "    with open(image_path, \"rb\") as f:\n",
        "        return f.read()\n",
        "\n",
        "# === GPT-4o Inference\n",
        "def get_latex_from_gpt(image_path):\n",
        "    image_data = encode_image(image_path)\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": [\n",
        "                        {\"type\": \"text\", \"text\": \"Extract the optimization problem in this image and return only the LaTeX code. I want clean latex in a single line without any begin and end tags, without dollar sign. Example: \\\\text{max} \\\\quad & 6x_1 + \\\\log(x_2 + 1) \\\\\\\\ \\\\text{st} \\\\quad & e^{x_1} + 2x_2 + w_1 = 17 \\\\\\\\ & x_1, x_2, w_1, w_2, w_3 \\\\geq 0.\"},\n",
        "                        {\"type\": \"image_url\", \"image_url\": {\n",
        "                            \"url\": \"data:image/jpeg;base64,\" + base64.b64encode(image_data).decode(\"utf-8\")\n",
        "                        }}\n",
        "                    ]\n",
        "                }\n",
        "            ],\n",
        "            max_tokens=1000\n",
        "        )\n",
        "        return response.choices[0].message.content.strip()\n",
        "    except Exception as e:\n",
        "        print(f\"Error for {image_path}: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "# === Load Files\n",
        "image_files = sorted([\n",
        "    f for f in os.listdir(image_folder)\n",
        "    if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))\n",
        "], key=lambda x: int(os.path.splitext(x)[0]))\n",
        "\n",
        "with open(gt_txt_file, \"r\", encoding=\"utf-8\") as f:\n",
        "    gt_lines = [line.strip() for line in f.readlines()]\n",
        "\n",
        "assert len(image_files) == len(gt_lines), \"Mismatch between images and ground truth\"\n",
        "\n",
        "if max_samples:\n",
        "    image_files = image_files[:max_samples]\n",
        "    gt_lines = gt_lines[:max_samples]\n",
        "\n",
        "# === Run GPT-4o + Evaluation\n",
        "bleu_scores = []\n",
        "truth_and_preds = []\n",
        "\n",
        "with open(output_txt, \"w\", encoding=\"utf-8\") as fout:\n",
        "    for i, fname in enumerate(tqdm(image_files)):\n",
        "        img_path = os.path.join(image_folder, fname)\n",
        "        gt = gt_lines[i]\n",
        "        pred = get_latex_from_gpt(img_path)\n",
        "\n",
        "        bleu = compute_individual_metrics(pred, gt)\n",
        "        bleu_scores.append(bleu)\n",
        "        truth_and_preds.append((gt, pred))\n",
        "\n",
        "        fout.write(f\"image: {fname}\\n\")\n",
        "        fout.write(f\"gt    : {gt}\\n\")\n",
        "        fout.write(f\"prediction: {pred}\\n\")\n",
        "        fout.write(f\"bleu  : {bleu:.4f}\\n\")\n",
        "        fout.write(\"-\" * 60 + \"\\n\")\n",
        "\n",
        "# === Final Metrics\n",
        "avg_bleu = sum(bleu_scores) / len(bleu_scores) if bleu_scores else 0.0\n",
        "cer_score = compute_cer(truth_and_preds)\n",
        "\n",
        "with open(output_txt, \"a\", encoding=\"utf-8\") as fout:\n",
        "    fout.write(\"\\n=== Summary ===\\n\")\n",
        "    fout.write(f\"Total Samples     : {len(bleu_scores)}\\n\")\n",
        "    fout.write(f\"Average BLEU      : {avg_bleu:.4f}\\n\")\n",
        "    fout.write(f\"Average CER       : {cer_score:.4f}\\n\")\n",
        "\n",
        "print(\"\\n=== Evaluation Complete ===\")\n",
        "print(f\"Samples evaluated : {len(bleu_scores)}\")\n",
        "print(f\"Average BLEU      : {avg_bleu:.4f}\")\n",
        "print(f\"Average CER       : {cer_score:.4f}\")\n",
        "print(f\"Output saved to   : {output_txt}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YF-r050oUaYh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
